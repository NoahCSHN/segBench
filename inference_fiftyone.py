import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import numpy as np
import fiftyone as fo
from tqdm import tqdm

# === å¼•å…¥ä½ ä¹‹å‰çš„æ¨¡å‹å®šä¹‰ ===
# ç¡®ä¿ models æ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•ä¸‹
from models.backbones.dinov3 import Dinov3TransformerBackbone
from models.heads.my_head import SimpleSegHead
from models.heads.head_ppm import ContextSegHead

# ================= é…ç½®åŒºåŸŸ =================
# 1. è·¯å¾„é…ç½®
# éªŒè¯é›†å›¾ç‰‡çš„æ–‡ä»¶å¤¹ (åªæ”¾å›¾ç‰‡ï¼Œä¸éœ€è¦æ”¾æ ‡æ³¨)
VAL_IMAGE_DIR = "/home/wayrobo/0_code/segment-anything-2/sav_dataset/0_poly_DrivingRange/workflow" 
# è®­ç»ƒå¥½çš„æƒé‡æ–‡ä»¶
CHECKPOINT_PATH = "checkpoints/VITS16_PPM_epoch_10.pth" # æ›¿æ¢ä¸ºä½ å®é™…çš„æƒé‡è·¯å¾„
# DINOv3 é¢„è®­ç»ƒæƒé‡è·¯å¾„ (Backbone åˆå§‹åŒ–è¿˜éœ€è¦ç”¨åˆ°å®ƒ)
DINO_WEIGHT_PATH = "/home/wayrobo/0_code/dinov3/pretrained/dinov3_vits16_pretrain_lvd1689m-08c60483.pth" 
# fiftyone dataset name
FIFTYONE_DATASET_NAME = "DINOV3_VITS16_PPM_GOLF_WORKFLOW"

# 2. æ¨¡å‹å‚æ•° (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)
IMG_SIZE = 512
NUM_CLASSES = 9
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# 3. ç±»åˆ«æ˜ å°„ (ç”¨äº FiftyOne æ˜¾ç¤ºå›¾ä¾‹)
# Key: é¢„æµ‹çš„ ID (0-8), Value: ç±»åˆ«åç§°
ID_TO_LABEL = {
    0: "static.field",
    1: "static.puddle",
    2: "static.structure",
    3: "static.vegatation",
    4: "dynamic.vehicle",
    5: "static.wayrobo",
    6: "dynamic.human",
    7: "dynamic.backet",
    8: "static.marker"
}
# ===========================================

def get_model():
    """é‡å»ºæ¨¡å‹ç»“æ„å¹¶åŠ è½½è®­ç»ƒæƒé‡"""
    print("æ­£åœ¨æ„å»ºæ¨¡å‹...")
    backbone = Dinov3TransformerBackbone(
        weight_path=DINO_WEIGHT_PATH,
        model_type='vit', # ç¡®ä¿ä¸è®­ç»ƒæ—¶ä¸€è‡´
        img_size=IMG_SIZE
    )
    head = ContextSegHead(
        in_channels=backbone.embed_dim, 
        num_classes=NUM_CLASSES
    )
    
    # å®šä¹‰ç®€å•çš„åŒ…è£…ç±» (ä¸ trains.py é‡Œçš„ SegModel ä¸€è‡´)
    class SegModel(nn.Module):
        def __init__(self, backbone, head):
            super().__init__()
            self.backbone = backbone
            self.head = head
        
        def forward(self, x):
            feats = self.backbone(x)
            logits = self.head(feats)
            return logits

    model = SegModel(backbone, head)
    
    # åŠ è½½ä½ è®­ç»ƒå¥½çš„ Checkpoint
    print(f"åŠ è½½è®­ç»ƒæƒé‡: {CHECKPOINT_PATH}")
    checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')
    model.load_state_dict(checkpoint)
    model.to(DEVICE)
    model.eval()
    return model

def main():
    # 1. å‡†å¤‡æ¨¡å‹
    model = get_model()

    # 2. å®šä¹‰é¢„å¤„ç† (å¿…é¡»ä¸è®­ç»ƒæ—¶çš„ transform ä¸€è‡´)
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # 3. åˆ›å»º FiftyOne æ•°æ®é›†
    dataset_name = FIFTYONE_DATASET_NAME
    
    # å¦‚æœæ•°æ®é›†å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ (æ–¹ä¾¿é‡å¤è¿è¡Œ)
    if dataset_name in fo.list_datasets():
        fo.delete_dataset(dataset_name)
    
    dataset = fo.Dataset(dataset_name)
    
    # 4. å¼€å§‹æ¨ç†
    image_files = [f for f in os.listdir(VAL_IMAGE_DIR) if f.endswith(('.jpg', '.png', '.jpeg'))]
    image_files.sort()
    
    samples = []
    print(f"å¼€å§‹æ¨ç† {len(image_files)} å¼ å›¾ç‰‡...")

    with torch.no_grad():
        for img_file in tqdm(image_files):
            img_path = os.path.join(VAL_IMAGE_DIR, img_file)
            
            # --- è¯»å–ä¸é¢„å¤„ç† ---
            original_img = Image.open(img_path).convert('RGB')
            w, h = original_img.size # è®°å½•åŸå›¾å°ºå¯¸
            
            input_tensor = transform(original_img).unsqueeze(0).to(DEVICE) # (1, 3, 512, 512)
            
            # --- æ¨¡å‹æ¨ç† ---
            logits = model(input_tensor) # (1, 9, 36, 36) (å–å†³äº Head è¾“å‡ºå°ºå¯¸)
            
            # ä¸Šé‡‡æ ·å› **åŸå›¾å°ºå¯¸** (è¿™ä¸€ç‚¹å¯¹å¯è§†åŒ–å¾ˆé‡è¦)
            # æˆ‘ä»¬ç›´æ¥æ’å€¼åˆ° (h, w)
            logits = F.interpolate(logits, size=(h, w), mode='bilinear', align_corners=False)
            
            # è·å–é¢„æµ‹ç»“æœ (Argmax) -> (h, w)
            pred_mask = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)
            
            # --- åˆ›å»º FiftyOne æ ·æœ¬ ---
            sample = fo.Sample(filepath=img_path)
            
            # æ·»åŠ é¢„æµ‹ç»“æœ
            # FiftyOne åªéœ€è¦äºŒç»´çš„ uint8 æ•°ç»„å³å¯
            sample["prediction"] = fo.Segmentation(
                mask=pred_mask
            )
            
            samples.append(sample)

    # 5. æ·»åŠ æ ·æœ¬åˆ°æ•°æ®é›†
    dataset.add_samples(samples)
    
    # 6. è®¾ç½®å¯è§†åŒ–æ ·å¼ (Mask Targets)
    # è®© FiftyOne çŸ¥é“ ID 5 æ˜¯ "wayrobo" å¹¶è‡ªåŠ¨åˆ†é…é¢œè‰²
    dataset.default_mask_targets = ID_TO_LABEL
    
    # æŒä¹…åŒ–ä¿å­˜
    dataset.save()

    print("æ¨ç†å®Œæˆï¼æ­£åœ¨å¯åŠ¨ FiftyOne App...")
    
    # 7. å¯åŠ¨ App
    session = fo.launch_app(dataset, port=5151, address="0.0.0.0", auto=False)
    
    # 8. å®‰å…¨æŒ‚èµ·
    try:
        session.wait()
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ­£åœ¨å…³é—­...")
    finally:
        session.close()
        print("âœ… æœåŠ¡å·²å®‰å…¨å…³é—­ã€‚")

if __name__ == "__main__":
    main()
